generator:
  agents_per_team: 3
  arena:
    height: 14.0
    obstacle_count: 0
    obstacle_radius: 1.0
    obstacle_seed: 0
    width: 20.0
  dt: 0.25
  lag:
    fixed_k: 2
    mode: fixed
    per_agent_hetero: false
  mixture:
    init_weights:
    - 0.5
    - 0.5
    min_dwell_steps: 8
    scheduler: stagnant
  opponent_mixture:
    init_weights:
    - 1.0
    - 0.0
    scheduler: stagnant
  opponent_policies:
  - family: random
    id: op_base0
    noise_sigma: 0.08
    regionizer:
      centers_per_dim:
      - 2048
      - 1
      length_scale: 0.25
      type: window_hash
    stochastic: true
  - family: random
    id: op_base1
    noise_sigma: 0.05
    regionizer:
      centers_per_dim:
      - 2048
      - 1
      length_scale: 0.2
      type: window_hash
    stochastic: true
  policies:
  - family: proto_actions
    id: P0
    noise:
      sigma: 0.1
      type: gaussian
    prototypes:
      components: 4
      style: random
    regionizer:
      length_scale: 0.7
      smoother: rbf
      type: smoothed
    stochastic: false
  - family: proto_actions
    id: P1
    noise:
      sigma: 0.12
      type: gaussian
    prototypes:
      components: 4
      style: random
    regionizer:
      length_scale: 0.8
      smoother: rbf
      type: smoothed
    stochastic: true
  seed: 421
  selected_team: 0
  steps: 400
  teams: 2
  window: 6
gradient_optimization:
  device: cuda
  enabled: true
  targets:
  - lr: 0.01
    max_iters: 80
    shift_kind: state_only
    target_divergence: 0.05
    tolerance: 0.02
  - lr: 0.01
    max_iters: 80
    shift_kind: state_only
    target_divergence: 0.1
    tolerance: 0.02
  - lr: 0.01
    max_iters: 80
    shift_kind: state_only
    target_divergence: 0.15
    tolerance: 0.02
  - lr: 0.01
    max_iters: 80
    shift_kind: state_only
    target_divergence: 0.2
    tolerance: 0.02
  - lr: 0.01
    max_iters: 80
    shift_kind: state_action
    target_divergence: 0.05
    tolerance: 0.02
  - lr: 0.01
    max_iters: 80
    shift_kind: state_action
    target_divergence: 0.1
    tolerance: 0.02
  - lr: 0.01
    max_iters: 80
    shift_kind: state_action
    target_divergence: 0.15
    tolerance: 0.02
  - lr: 0.01
    max_iters: 80
    shift_kind: state_action
    target_divergence: 0.2
    tolerance: 0.02
  - lr: 0.01
    max_iters: 80
    shift_kind: policy
    target_divergence: 0.05
    tolerance: 0.02
  - lr: 0.01
    max_iters: 80
    shift_kind: policy
    target_divergence: 0.1
    tolerance: 0.02
  - lr: 0.01
    max_iters: 80
    shift_kind: policy
    target_divergence: 0.15
    tolerance: 0.02
  - lr: 0.01
    max_iters: 80
    shift_kind: policy
    target_divergence: 0.2
    tolerance: 0.02
policy_shift_configs:
  policy_050:
    mixture:
      init_weights:
      - 0.55
      - 0.45
  policy_100:
    mixture:
      init_weights:
      - 0.6
      - 0.4
  policy_150:
    mixture:
      init_weights:
      - 0.7
      - 0.3
  policy_200:
    mixture:
      init_weights:
      - 0.8
      - 0.2
splits:
  test_episodes: 600
  train_episodes: 1200
  val_episodes: 300
